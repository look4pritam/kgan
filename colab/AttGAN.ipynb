{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AttGAN.ipynb","provenance":[{"file_id":"https://github.com/look4pritam/kgan/blob/master/colab/DCGAN.ipynb","timestamp":1595579973072},{"file_id":"https://github.com/look4pritam/UVSS/blob/master/UVSS.ipynb","timestamp":1594807354968}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"s3bl0CVR-OYe","colab_type":"text"},"source":["# AttGAN\n","# Abstract - IEEE Xplore\n","Facial attribute editing aims to manipulate single or multiple attributes on a given face image, i.e., to generate a new face image with desired attributes while preserving other details. Recently, the generative adversarial net (GAN) and encoder-decoder architecture are usually incorporated to handle this task with promising results. Based on the encoder-decoder architecture, facial attribute editing is achieved by decoding the latent representation of a given face conditioned on the desired attributes. Some existing methods attempt to establish an attribute-independent latent representation for further attribute editing. However, such attribute-independent constraint on the latent representation is excessive because it restricts the capacity of the latent representation and may result in information loss, leading to over-smooth or distorted generation. Instead of imposing constraints on the latent representation, in this work, we propose to apply an attribute classification constraint to the generated image to just guarantee the correct change of desired attributes, i.e., to change what you want. Meanwhile, the reconstruction learning is introduced to preserve attribute-excluding details, in other words, to only change what you want. Besides, the adversarial learning is employed for visually realistic editing. These three components cooperate with each other forming an effective framework for high quality facial attribute editing, referred as AttGAN. Furthermore, the proposed method is extended for attribute style manipulation in an unsupervised manner. Experiments on two wild datasets, CelebA and LFW, show that the proposed method outperforms the state-of-the-art on realistic attribute editing with other facial details well preserved.\n","\n","# References\n","* [AttGAN: Facial Attribute Editing by Only Changing What You Want - IEEE Xplore](https://ieeexplore.ieee.org/document/8718508)\n","* [AttGAN: Facial Attribute Editing by Only Changing What You Want - arXiv.org](https://arxiv.org/abs/1711.10678)\n","* [AttGAN-Tensorflow](https://github.com/LynnHo/AttGAN-Tensorflow)\n","* [AttGAN-PyTorch](https://github.com/elvisyjlin/AttGAN-PyTorch)\n","* [AttGAN - github.com](https://github.com/look4pritam/kgan)"]},{"cell_type":"markdown","metadata":{"id":"vVmhPdH-qhaQ","colab_type":"text"},"source":["# Check GPU version."]},{"cell_type":"code","metadata":{"id":"CWO5it97qidT","colab_type":"code","colab":{}},"source":["!nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pLY-O5f_aDel","colab_type":"text"},"source":["# Clone kgan git repository."]},{"cell_type":"code","metadata":{"id":"7iX5wfL9_act","colab_type":"code","colab":{}},"source":["!git clone https://github.com/look4pritam/kgan.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HRoA21iaCB2_","colab_type":"code","colab":{}},"source":["!ls -al"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d9I1_1mEaKaR","colab_type":"text"},"source":["# Set the root directory."]},{"cell_type":"code","metadata":{"id":"awn7Chl-CUaC","colab_type":"code","colab":{}},"source":["import os\n","\n","root_dir = '/content/kgan'\n","os.chdir(root_dir)\n","\n","!ls -al"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q81U6CZb8ahz","colab_type":"text"},"source":["# Process CelebA dataset."]},{"cell_type":"markdown","metadata":{"id":"AZs5GsMS7xTV","colab_type":"text"},"source":["### Download aligned CelebA dataset"]},{"cell_type":"code","metadata":{"id":"I7aOa4yH72tI","colab_type":"code","colab":{}},"source":["!gdown --id 1diaLDdB-dNMsPhJX0uco4155ghi4KMXK # 1z5bpHVrciXmE8obe8NeYa3u9zWvdLWwS"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g6IDiBaa8Dye","colab_type":"code","colab":{}},"source":["!ls -al"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"owVtQFjc79EC","colab_type":"text"},"source":["### Extract the dataset."]},{"cell_type":"code","metadata":{"id":"04La7Bnn7-Du","colab_type":"code","colab":{}},"source":["!tar -xzf img_align_celeba.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JB3Jz8l08Cz3","colab_type":"code","colab":{}},"source":["!rm -rf img_align_celeba.tar.gz"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ls0asoIX8I42","colab_type":"text"},"source":["### Verify dataset contents."]},{"cell_type":"code","metadata":{"id":"Z-CI43xa8J5W","colab_type":"code","colab":{}},"source":["!ls -al\n","!ls -al img_align_celeba\n","!ls -l img_align_celeba/images | wc -l"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mr1_SYfZbWOX","colab_type":"text"},"source":["# Train AttGAN model using CelebA dataset."]},{"cell_type":"markdown","metadata":{"id":"_PWnuupCXBe8","colab_type":"text"},"source":["### Update local repository."]},{"cell_type":"code","metadata":{"id":"xEpqXv4eaQa9","colab_type":"code","colab":{}},"source":["!git pull origin"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L_MJZUkRXGf-","colab_type":"text"},"source":["### Train the model."]},{"cell_type":"code","metadata":{"id":"fmEAKGApbXgT","colab_type":"code","colab":{}},"source":["!export PYTHONPATH=/content/kgan:$PYTHONPATH; \\\n","                  python kgan/train_model.py \\\n","                  --model attgan  \\\n","                  --dataset celeba \\\n","                  --model_shape 128 128 3 \\\n","                  --latent_dimension 40 \\\n","                  --learning_rate 0.0002 \\\n","                  --batch_size 32 \\\n","                  --maximum_epochs 60 \\\n","                  --discriminator_number 5 \\\n","                  --generator_number 1 \\\n","                  --loss_scan_frequency 10 \\\n","                  --save_frequency 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D0KkH1SaJ5EC","colab_type":"text"},"source":["# Visualize training graphs."]},{"cell_type":"code","metadata":{"id":"rSMIWStJMHIg","colab_type":"code","colab":{}},"source":["%reload_ext tensorboard\n","%tensorboard --logdir 'logs'"],"execution_count":null,"outputs":[]}]}