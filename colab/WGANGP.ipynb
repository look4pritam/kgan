{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WGANGP.ipynb","provenance":[{"file_id":"https://github.com/look4pritam/kgan/blob/7222f971f7e96351bf7046c043529b4d7b55168d/colab/WGANGP.ipynb","timestamp":1596538102058},{"file_id":"https://github.com/look4pritam/kgan/blob/master/colab/DCGAN.ipynb","timestamp":1595579973072},{"file_id":"https://github.com/look4pritam/UVSS/blob/master/UVSS.ipynb","timestamp":1594807354968}],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"s3bl0CVR-OYe","colab_type":"text"},"source":["# WGAN-GP \n","# Abstract - arXiv.org\n","Generative Adversarial Networks (GANs) are powerful generative models, but suffer from training instability. The recently proposed Wasserstein GAN (WGAN) makes progress toward stable training of GANs, but sometimes can still generate only low-quality samples or fail to converge. We find that these problems are often due to the use of weight clipping in WGAN to enforce a Lipschitz constraint on the critic, which can lead to undesired behavior. We propose an alternative to clipping weights: penalize the norm of gradient of the critic with respect to its input. Our proposed method performs better than standard WGAN and enables stable training of a wide variety of GAN architectures with almost no hyperparameter tuning, including 101-layer ResNets and language models over discrete data. We also achieve high quality generations on CIFAR-10 and LSUN bedrooms.\n","\n","#References\n","* [Improved Training of Wasserstein GANs - arxiv.org](https://arxiv.org/abs/1704.00028)\n","* [WGAN-GP - github.com](https://github.com/look4pritam/kgan)"]},{"cell_type":"markdown","metadata":{"id":"pLY-O5f_aDel","colab_type":"text"},"source":["# Clone kgan git repository."]},{"cell_type":"code","metadata":{"id":"7iX5wfL9_act","colab_type":"code","colab":{}},"source":["!git clone https://github.com/look4pritam/kgan.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HRoA21iaCB2_","colab_type":"code","colab":{}},"source":["!ls -al"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d9I1_1mEaKaR","colab_type":"text"},"source":["# Set the root directory."]},{"cell_type":"code","metadata":{"id":"awn7Chl-CUaC","colab_type":"code","colab":{}},"source":["import os\n","\n","root_dir = '/content/kgan'\n","os.chdir(root_dir)\n","\n","!ls -al"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Mr1_SYfZbWOX","colab_type":"text"},"source":["# Train WGAN-GP model using Fashion-MNIST dataset."]},{"cell_type":"markdown","metadata":{"id":"_PWnuupCXBe8","colab_type":"text"},"source":["### Update local repository."]},{"cell_type":"code","metadata":{"id":"xEpqXv4eaQa9","colab_type":"code","colab":{}},"source":["!git pull origin"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"L_MJZUkRXGf-","colab_type":"text"},"source":["### Train the model."]},{"cell_type":"code","metadata":{"id":"fmEAKGApbXgT","colab_type":"code","colab":{}},"source":["!export PYTHONPATH=/content/kgan:$PYTHONPATH; \\\n","                  python kgan/train_model.py \\\n","                  --model wgangp  \\\n","                  --dataset fashion_mnist \\\n","                  --model_shape 28 28 1 \\\n","                  --latent_dimension 62 \\\n","                  --learning_rate 0.0002 \\\n","                  --batch_size 64 \\\n","                  --maximum_epochs 20 \\\n","                  --start_epoch 0 \\\n","                  --discriminator_number 1 \\\n","                  --generator_number 1 \\\n","                  --save_frequency 1 \\\n","                  --loss_scan_frequency 100"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D0KkH1SaJ5EC","colab_type":"text"},"source":["# Visualize training graphs."]},{"cell_type":"code","metadata":{"id":"rSMIWStJMHIg","colab_type":"code","colab":{}},"source":["%reload_ext tensorboard\n","%tensorboard --logdir 'logs'"],"execution_count":null,"outputs":[]}]}